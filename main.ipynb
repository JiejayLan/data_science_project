{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import csv\n",
    "import warnings\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from keras import models, layers, optimizers, regularizers\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, GridSearchCV\n",
    "from keras import regularizers\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import datasets\n",
    "- We will import train, test1 and test2 dataset\n",
    "- Merge test1 and train dataset, in order to expend our train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "O3bd5Le9C1yG",
    "outputId": "01b85a52-799e-4075-ffce-c1820b0035c5",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['addr_unit', 'building_id', 'bedrooms', 'bathrooms', 'size_sqft',\n",
       "       'created_at', 'addr_street', 'addr_city', 'addr_zip', 'addr_lat',\n",
       "       'addr_lon', 'bin', 'bbl', 'floor_count', 'year_built', 'min_to_subway',\n",
       "       'has_doorman', 'has_elevator', 'has_fireplace', 'has_dishwasher',\n",
       "       'is_furnished', 'has_gym', 'allows_pets', 'has_washer_dryer',\n",
       "       'has_garage', 'has_roofdeck', 'has_concierge', 'has_pool', 'has_garden',\n",
       "       'has_childrens_playroom', 'rent', 'no_fee', 'description',\n",
       "       'neighborhood', 'borough', 'unit', 'floornumber', 'line'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv('https://grantmlong.com/data/SE_rents2018_train.csv', index_col=0)\n",
    "raw_test_df = pd.read_csv('https://grantmlong.com/data/SE_rents2018_test1.csv', index_col=0)\n",
    "raw_test2_df = pd.read_csv('https://grantmlong.com/data/SE_rents2018_test2.csv', index_col=0)\n",
    "raw_df = raw_df.append(raw_test_df)\n",
    "raw_df.head(20)\n",
    "raw_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xxSoiIKJC1yO"
   },
   "source": [
    "## Data Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "ql26Ay-HC1yI",
    "outputId": "33defc34-c066-4fc0-fd2b-f3d6438b6968"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>size_sqft</th>\n",
       "      <th>addr_zip</th>\n",
       "      <th>addr_lat</th>\n",
       "      <th>addr_lon</th>\n",
       "      <th>bin</th>\n",
       "      <th>bbl</th>\n",
       "      <th>floor_count</th>\n",
       "      <th>...</th>\n",
       "      <th>has_washer_dryer</th>\n",
       "      <th>has_garage</th>\n",
       "      <th>has_roofdeck</th>\n",
       "      <th>has_concierge</th>\n",
       "      <th>has_pool</th>\n",
       "      <th>has_garden</th>\n",
       "      <th>has_childrens_playroom</th>\n",
       "      <th>rent</th>\n",
       "      <th>no_fee</th>\n",
       "      <th>floornumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.400000e+04</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>1.399900e+04</td>\n",
       "      <td>1.400000e+04</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>12498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.542772e+06</td>\n",
       "      <td>1.661643</td>\n",
       "      <td>1.238929</td>\n",
       "      <td>848.388643</td>\n",
       "      <td>10681.801286</td>\n",
       "      <td>40.727746</td>\n",
       "      <td>-73.956776</td>\n",
       "      <td>2.368400e+06</td>\n",
       "      <td>2.285087e+09</td>\n",
       "      <td>10.233350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268500</td>\n",
       "      <td>0.170714</td>\n",
       "      <td>0.262643</td>\n",
       "      <td>0.208214</td>\n",
       "      <td>0.072357</td>\n",
       "      <td>0.133786</td>\n",
       "      <td>0.089571</td>\n",
       "      <td>3591.997214</td>\n",
       "      <td>0.495786</td>\n",
       "      <td>6.198232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.323673e+06</td>\n",
       "      <td>1.084151</td>\n",
       "      <td>0.550979</td>\n",
       "      <td>513.039489</td>\n",
       "      <td>592.728072</td>\n",
       "      <td>0.053635</td>\n",
       "      <td>0.042994</td>\n",
       "      <td>1.242507e+06</td>\n",
       "      <td>1.200828e+09</td>\n",
       "      <td>12.003629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443195</td>\n",
       "      <td>0.376273</td>\n",
       "      <td>0.440086</td>\n",
       "      <td>0.406045</td>\n",
       "      <td>0.259088</td>\n",
       "      <td>0.340434</td>\n",
       "      <td>0.285577</td>\n",
       "      <td>2874.099247</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.728606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.300000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10001.000000</td>\n",
       "      <td>40.573898</td>\n",
       "      <td>-74.168405</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.231400e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>604.000000</td>\n",
       "      <td>10023.000000</td>\n",
       "      <td>40.693256</td>\n",
       "      <td>-73.986095</td>\n",
       "      <td>1.052178e+06</td>\n",
       "      <td>1.011286e+09</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2250.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.545810e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>11103.000000</td>\n",
       "      <td>40.729048</td>\n",
       "      <td>-73.961554</td>\n",
       "      <td>3.018885e+06</td>\n",
       "      <td>3.006580e+09</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.267980e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>11218.000000</td>\n",
       "      <td>40.764801</td>\n",
       "      <td>-73.936080</td>\n",
       "      <td>3.325600e+06</td>\n",
       "      <td>3.050558e+09</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3900.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.877211e+07</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>11694.000000</td>\n",
       "      <td>40.909842</td>\n",
       "      <td>-73.730550</td>\n",
       "      <td>5.158986e+06</td>\n",
       "      <td>5.029930e+09</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id      bedrooms     bathrooms     size_sqft      addr_zip  \\\n",
       "count  1.400000e+04  14000.000000  14000.000000  14000.000000  14000.000000   \n",
       "mean   1.542772e+06      1.661643      1.238929    848.388643  10681.801286   \n",
       "std    4.323673e+06      1.084151      0.550979    513.039489    592.728072   \n",
       "min    7.300000e+01      0.000000      0.000000      0.000000  10001.000000   \n",
       "25%    6.231400e+04      1.000000      1.000000    604.000000  10023.000000   \n",
       "50%    2.545810e+05      2.000000      1.000000    800.000000  11103.000000   \n",
       "75%    8.267980e+05      2.000000      1.000000   1000.000000  11218.000000   \n",
       "max    1.877211e+07      8.000000     20.000000  10000.000000  11694.000000   \n",
       "\n",
       "           addr_lat      addr_lon           bin           bbl   floor_count  \\\n",
       "count  14000.000000  14000.000000  1.399900e+04  1.400000e+04  14000.000000   \n",
       "mean      40.727746    -73.956776  2.368400e+06  2.285087e+09     10.233350   \n",
       "std        0.053635      0.042994  1.242507e+06  1.200828e+09     12.003629   \n",
       "min       40.573898    -74.168405  1.000000e+06  0.000000e+00      0.000000   \n",
       "25%       40.693256    -73.986095  1.052178e+06  1.011286e+09      3.000000   \n",
       "50%       40.729048    -73.961554  3.018885e+06  3.006580e+09      5.000000   \n",
       "75%       40.764801    -73.936080  3.325600e+06  3.050558e+09     12.000000   \n",
       "max       40.909842    -73.730550  5.158986e+06  5.029930e+09     90.000000   \n",
       "\n",
       "       ...  has_washer_dryer    has_garage  has_roofdeck  has_concierge  \\\n",
       "count  ...      14000.000000  14000.000000  14000.000000   14000.000000   \n",
       "mean   ...          0.268500      0.170714      0.262643       0.208214   \n",
       "std    ...          0.443195      0.376273      0.440086       0.406045   \n",
       "min    ...          0.000000      0.000000      0.000000       0.000000   \n",
       "25%    ...          0.000000      0.000000      0.000000       0.000000   \n",
       "50%    ...          0.000000      0.000000      0.000000       0.000000   \n",
       "75%    ...          1.000000      0.000000      1.000000       0.000000   \n",
       "max    ...          1.000000      1.000000      1.000000       1.000000   \n",
       "\n",
       "           has_pool    has_garden  has_childrens_playroom          rent  \\\n",
       "count  14000.000000  14000.000000            14000.000000  14000.000000   \n",
       "mean       0.072357      0.133786                0.089571   3591.997214   \n",
       "std        0.259088      0.340434                0.285577   2874.099247   \n",
       "min        0.000000      0.000000                0.000000   1250.000000   \n",
       "25%        0.000000      0.000000                0.000000   2250.000000   \n",
       "50%        0.000000      0.000000                0.000000   2900.000000   \n",
       "75%        0.000000      0.000000                0.000000   3900.000000   \n",
       "max        1.000000      1.000000                1.000000  50000.000000   \n",
       "\n",
       "             no_fee   floornumber  \n",
       "count  14000.000000  12498.000000  \n",
       "mean       0.495786      6.198232  \n",
       "std        0.500000      7.728606  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      2.000000  \n",
       "50%        0.000000      3.000000  \n",
       "75%        1.000000      6.000000  \n",
       "max        1.000000     78.000000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "csEm7f26C1yS",
    "outputId": "d3a30c17-b4c6-45a3-c642-39b7f6069656"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 38)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "colab_type": "code",
    "id": "I9hONCStC1yP",
    "outputId": "7d3827da-d02a-4614-9981-6070be31b237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14000 entries, 7236931 to 7463404\n",
      "Data columns (total 38 columns):\n",
      "addr_unit                 13890 non-null object\n",
      "building_id               14000 non-null int64\n",
      "bedrooms                  14000 non-null int64\n",
      "bathrooms                 14000 non-null float64\n",
      "size_sqft                 14000 non-null float64\n",
      "created_at                14000 non-null object\n",
      "addr_street               14000 non-null object\n",
      "addr_city                 14000 non-null object\n",
      "addr_zip                  14000 non-null int64\n",
      "addr_lat                  14000 non-null float64\n",
      "addr_lon                  14000 non-null float64\n",
      "bin                       13999 non-null float64\n",
      "bbl                       14000 non-null int64\n",
      "floor_count               14000 non-null float64\n",
      "year_built                13530 non-null float64\n",
      "min_to_subway             13857 non-null float64\n",
      "has_doorman               14000 non-null int64\n",
      "has_elevator              14000 non-null int64\n",
      "has_fireplace             14000 non-null int64\n",
      "has_dishwasher            14000 non-null int64\n",
      "is_furnished              14000 non-null int64\n",
      "has_gym                   14000 non-null int64\n",
      "allows_pets               14000 non-null int64\n",
      "has_washer_dryer          14000 non-null int64\n",
      "has_garage                14000 non-null int64\n",
      "has_roofdeck              14000 non-null int64\n",
      "has_concierge             14000 non-null int64\n",
      "has_pool                  14000 non-null int64\n",
      "has_garden                14000 non-null int64\n",
      "has_childrens_playroom    14000 non-null int64\n",
      "rent                      14000 non-null int64\n",
      "no_fee                    14000 non-null int64\n",
      "description               13984 non-null object\n",
      "neighborhood              13997 non-null object\n",
      "borough                   14000 non-null object\n",
      "unit                      13886 non-null object\n",
      "floornumber               12498 non-null float64\n",
      "line                      9865 non-null object\n",
      "dtypes: float64(9), int64(20), object(9)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "bQBnI2n0FuHJ",
    "outputId": "9a62644e-70ac-4531-c6f8-96813f039d8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22f8af54080>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_df['rent'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cN1cvd5g0lcL"
   },
   "source": [
    "### Seperate all features into continuous, categorical and binary features.\n",
    "\n",
    "For those none relatived features as below, we have excluded them from the features grouping: \n",
    "- addr_unit: no relationship\n",
    "- building_id: no relationship\n",
    "- addr_lat: hard to analyze latitude\n",
    "- addr_lon: hard to analyze longtitude\n",
    "- bin: need to wait for external dataset\n",
    "- bbl: need to wait for external dataset\n",
    "- description: hard to build a NLP model\n",
    "- unit: no relationship\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ce4l5HZNModF"
   },
   "outputs": [],
   "source": [
    "continuous_features =['bathrooms','bedrooms','size_sqft','floor_count','year_built','min_to_subway','floornumber' ]\n",
    "caterigal_features =['addr_street','addr_city','addr_zip','neighborhood','borough','line' ]\n",
    "binary_features = ['has_doorman', 'has_elevator', 'has_fireplace', 'has_dishwasher','is_furnished', 'has_gym', 'allows_pets', \n",
    "                   'has_washer_dryer','has_garage', 'has_roofdeck', 'has_concierge', 'has_pool', 'has_garden',\n",
    "                   'has_childrens_playroom', 'no_fee', ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bp674gXgC1yy"
   },
   "source": [
    "## Import external dataset from Internal Revenue Service\n",
    " - We will import the 2017 individual income Tax statistic dataset from IRS website(https://www.irs.gov/pub/irs-soi/17zpallagi.csv).\n",
    " - We will expend a new feature: **average_income** based on zipcode to our raw dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ySvUva5SC1yz"
   },
   "outputs": [],
   "source": [
    "raw_income_data=pd.read_csv('https://www.irs.gov/pub/irs-soi/17zpallagi.csv', index_col=0)\n",
    "raw_income_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4OwGK7NMC1y4"
   },
   "outputs": [],
   "source": [
    "raw_income_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income Dataset Description \n",
    "This dataset comes from the IRS website's 2017 ZIP Code Data (SOI) about Individual Income Tax Statistics.\n",
    "According to the documentation's overview,the Statistics of Income (SOI) Division’s ZIP code data is tabulated using individual income tax returns (Forms 1040) filed with the Internal Revenue Service (IRS) during the 12-month period, January 1, 2018 to December 31, 2018.\n",
    "The original dataset contains many income and Tax Items, we only keep the ones that are relevant: \n",
    "- STATEFIPS:The State Federal Information Processing System (FIPS) code\n",
    "- STATE: The State associated with the ZIP code\n",
    "- ZIPCODE: 5-digit Zip code\n",
    "- agi_stub: Size of adjusted gross income\n",
    "- N1: Total number of returns\n",
    "- A02650: Number of returns with total income\n",
    "\n",
    "Our goal is to find the average income of each zipcode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the raw income data and rename feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_income_data = raw_income_data.loc[raw_income_data['STATE']=='NY']\n",
    "raw_income_data.rename(columns = {'N1':'total_returns', 'A02650':'total_income'}, inplace = True) \n",
    "raw_income_data = raw_income_data[['STATE','zipcode','agi_stub','total_returns', 'total_income']]\n",
    "raw_income_data = raw_income_data.loc[raw_income_data['zipcode']<99999]\n",
    "raw_income_data = raw_income_data.loc[raw_income_data['zipcode']>0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate the average income by zip code\n",
    "Each zip code has 6 different sizes of adjusted gross income which means we have 6 different number of total returns and total income for one zip code.\n",
    "By using the np.where and sum function, we can obtain the sum of income and sum of returns for each zip code. The income of the original dataset was in thousands of dollar so we need to multiply the sum of income by 1000 and then find the average. Since some zip code was not in the original set, we ingore those average that is NaN and only write the meaningful averages to csv file for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate average income \n",
    "- Export to ny_income_2017.csv for storage\n",
    "- For next time, no need to import the raw_income_dataset again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_income = pd.DataFrame({'addr_zip':[],'zip_average_income':[]})\n",
    "\n",
    "def calculate_avg_income():\n",
    "    global average_income\n",
    "    for zipcode in range(10001, 14906):\n",
    "        current_sum=np.where(raw_income_data['zipcode']==zipcode, raw_income_data['total_income'],0).sum()\n",
    "        current_returns=np.where(raw_income_data['zipcode']==zipcode, raw_income_data['total_returns'],0).sum() \n",
    "        if(current_returns <=0 or current_sum<=0):\n",
    "            continue\n",
    "        avg_income=(current_sum*1000)/current_returns\n",
    "        new_row={'addr_zip':zipcode,'zip_average_income':avg_income}\n",
    "        average_income=average_income.append(new_row,ignore_index=True)           \n",
    "calculate_avg_income()\n",
    "average_income.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - We realize that the income dataset is missing all income data between zipcode 11239 - 11354, we will take an averge of zipcode income for 11239 and 11354 to replace any zipcode income in between \n",
    " - In our training and testing dataset, only the zipcode income 11249 is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(set(raw_df['addr_zip']) - set(average_income['addr_zip'])))\n",
    "print(list(set(raw_test_df['addr_zip']) - set(average_income['addr_zip'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insert a new row for zipcode income 11249 into the average_income dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_income = (average_income.loc[(average_income['addr_zip']==11239)].iloc[0]['zip_average_income'] +\n",
    "             average_income.loc[(average_income['addr_zip']==11354)].iloc[0]['zip_average_income'])/2\n",
    "new_row = {'addr_zip':11249,'zip_average_income':avg_income}\n",
    "average_income=average_income.append(new_row,ignore_index=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the raw train  dataset with the income dataset by addr_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test2_df=raw_test_df.reset_index().merge(average_income, how=\"left\",on='addr_zip').set_index('rental_id')\n",
    "raw_df=raw_df.reset_index().merge(average_income, how=\"left\",on='addr_zip').set_index('rental_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find zip_average_income and rent cooleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features.append('zip_average_income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_df = raw_df[['zip_average_income','rent']]\n",
    "continuous_df.corr()['rent'][:-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The correlation between zip_average_income and rent is 0.393228, it is good enough to consider as a important feature that might impact the rent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Handling missing data\n",
    "In order to handle missing data in this dataset, we frist find and count all the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the result,there are missing data appearing on: \n",
    "- addr_unit\n",
    "- bin \n",
    "- year_built \n",
    "- min_to_subway \n",
    "- description \n",
    "- neighborhood \n",
    "- unit \n",
    "- floornumber \n",
    "- line \n",
    "\n",
    "Continuous features floornumber, year_built and min_to_subway has impact on the rent, so we will fill with mode or mean. For catagorigious feature neighborhood, we will not use it in building model, because it has too many possible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_df = raw_df\n",
    "\n",
    "md_df['floornumber'].fillna(md_df['floornumber'].mode()[0], inplace=True)\n",
    "raw_test2_df['floornumber'].fillna(raw_test2_df['floornumber'].mode()[0], inplace=True)\n",
    "\n",
    "md_df['min_to_subway'].fillna(md_df['min_to_subway'].mean(), inplace=True)\n",
    "raw_test2_df['min_to_subway'].fillna(raw_test2_df['min_to_subway'].mean(), inplace=True)\n",
    "\n",
    "md_df['year_built'].fillna(md_df['year_built'].mean(), inplace=True)\n",
    "raw_test2_df['year_built'].fillna(raw_test2_df['year_built'].mean(), inplace=True)\n",
    "\n",
    "print(\"original shape of dataset:\",raw_df.shape)\n",
    "print(\"shape of dataset after handling missing data, should stay the same:\",md_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in continuous_features:\n",
    "    md_df.plot.scatter(feature, 'rent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_df[md_df['rent']>40000].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**drop size_sqrt = 0 for now, since there are 713 rows, might replace with mode when creating models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(md_df, feature, low_value, high_value):\n",
    "    print(feature, ': ', md_df.shape)\n",
    "    md_df = md_df[md_df[feature]>low_value]\n",
    "    md_df = md_df[md_df[feature]<=high_value]\n",
    "    md_df.reset_index(drop=True,inplace=True)\n",
    "    print(feature, ': ', md_df.shape)\n",
    "    return md_df\n",
    "\n",
    "md_df = remove_outliers(md_df, 'rent', 0, 40000)\n",
    "md_df = remove_outliers(md_df, 'bathrooms', 0, 12)\n",
    "md_df = remove_outliers(md_df, 'size_sqft', 0, 10000)\n",
    "md_df = remove_outliers(md_df, 'year_built', 1700, 2019)\n",
    "md_df = remove_outliers(md_df, 'min_to_subway', 0, 60)\n",
    "md_df = remove_outliers(md_df, 'floornumber', 0, 60)\n",
    "\n",
    "md_df['year_built'] = 2019 - md_df['year_built'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical feature and drop useless features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs = np.array(md_df['borough'].unique())\n",
    "\n",
    "for borough in boroughs:\n",
    "    md_df[borough] = md_df['borough'].apply(lambda x : int(x == borough))\n",
    "    raw_test2_df[borough] = raw_test2_df['borough'].apply(lambda x : int(x == borough))\n",
    "\n",
    "features_notNeed = ['addr_unit', 'building_id', 'created_at', 'addr_street', 'addr_city', 'addr_zip', 'bin', 'bbl', 'description', \\\n",
    "                    'neighborhood', 'unit', 'borough', 'line']\n",
    "\n",
    "md_df = md_df.drop(features_notNeed, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pair coorelation for continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_df = md_df[continuous_features+['rent']]\n",
    "continuous_df.corr()['rent'][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check coorelation for binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_df[binary_features+['rent']].corr()['rent'][:-1]\n",
    "coor_results= []\n",
    "\n",
    "for feature in binary_features:\n",
    "  df = raw_df.groupby([feature]).aggregate(['mean'])['rent']\n",
    "  df[feature]= df.index\n",
    "  coor_results.append(df.corr().iloc[0][1])\n",
    "coor_df = pd.DataFrame({'Coorelation': coor_results,'Feature':binary_features})\n",
    "coor_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the correlation table, all binrary features highly affected the rents. When we build the models, we should include all binary features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Models\n",
    " - We will be using cross validation to evaluate the performances of our all modles,and then deciding which should be the most suitable one, thus we will first create a function called get_cv_results to obtain the cv_performance.\n",
    " - we will try 5 different basic categorical models:`multiple regression, decision tree, random froest, Gradient Boosting Regression and Neural Network`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_df = shuffle(md_df).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(md_df.columns)\n",
    "features.remove('rent')\n",
    "k_fold = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_results(regressor):\n",
    "    \n",
    "    results = []\n",
    "    for train, test in k_fold.split(md_df):\n",
    "        regressor.fit(md_df.loc[train, features], md_df.loc[train, 'rent'])\n",
    "        y_predicted = regressor.predict(md_df.loc[test, features])\n",
    "        accuracy = mean_squared_error(md_df.loc[test, 'rent'], y_predicted)**0.5\n",
    "        results.append(accuracy)\n",
    "\n",
    "    return np.mean(results), np.std(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radnom Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest = RandomForestRegressor(\n",
    "    random_state=11, \n",
    "    max_depth=10,\n",
    "    n_estimators=200\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cv_results(rforest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest.fit(md_df[features], md_df['rent'])  \n",
    "for feature,score in sorted(zip(features,rforest.feature_importances_), key=lambda x:x[1], reverse=True):\n",
    "    print(feature, ' ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Regression\n",
    " - Multiple regression is an extension of simple linear regression. It is used when we want to predict the value of a variable based on the value of two or more other variables\n",
    " - We will based on p value to choose significant variables(p<0.1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_reg_features = features[:]\n",
    "x = md_df[features] \n",
    "y = md_df['rent']\n",
    "est = sm.OLS(y, x).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see, variables has_garden and year_built have P value > 0.1\n",
    "- After we remove these two variables, all P values are < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_reg_features.remove('has_garden')\n",
    "mul_reg_features.remove('year_built')\n",
    "x = md_df[mul_reg_features] \n",
    "y = md_df['rent']\n",
    "est = sm.OLS(y, x).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_reg = LinearRegression().fit(md_df[mul_reg_features], md_df['rent'])\n",
    "get_cv_results(mul_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regression\n",
    "For the gradient boosting regressor we will first set up the hyperparameter max_depth=5 to avoid overfitting, will adjust more hyperparameter as we move on to improve the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrdemo = GradientBoostingRegressor(\n",
    "    max_depth=5,\n",
    "    n_estimators=100\n",
    ")\n",
    "\n",
    "get_cv_results(gbrdemo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameters\n",
    "Now let's use GridSearchCV form sci-kit learn model_selection to tune the hyperparameters, and find the most suitable one for our Gradient Boosting Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning the hyperparameters based on a cross-validation subset (cv)\n",
    "# cited link: link: https://shankarmsy.github.io/stories/gbrt-sklearn.html\n",
    "\n",
    "def GradientBooster():\n",
    "    \n",
    "    param_grid={'n_estimators':[100],\n",
    "            'learning_rate': [0.1, 0.05, 0.01],\n",
    "            'max_depth':[4, 5, 6],\n",
    "            'min_samples_leaf':[3, 5, 9],\n",
    "           }\n",
    "    \n",
    "    # choose cross validation generator and use ShuffleSplit which randomly shuffles and selects Train and CV sets\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=.25, random_state=0)\n",
    "    \n",
    "    classifier = GridSearchCV(estimator = GradientBoostingRegressor(), param_grid=param_grid, n_jobs=4, cv=cv)\n",
    "    \n",
    "    classifier.fit(md_df[features], md_df['rent'])  \n",
    "    return classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this function takes too long to run, it will waste a lot of time during development,\n",
    "# so we will just record the result for further usage. -----Runmin 11/18/19\n",
    "\"\"\"\n",
    "best_est=GradientBooster()\n",
    "\n",
    "print(\"Best Estimator Parameters:\")\n",
    "print(\"n_estimators: \",best_est['n_estimators'])\n",
    "print(\"max_depth: \", best_est['max_depth'])\n",
    "print(\"Learning Rate: \", best_est['learning_rate'])\n",
    "print(\"min_samples_leaf: \", best_est['min_samples_leaf'])\n",
    "\"\"\"\n",
    "print(\"Since this function takes too long to run, it will waste a lot of time during development,\\\n",
    "      \\nso we will just record the result for further usage:\")\n",
    "print(\"\\nBest Estimator Parameters:\")\n",
    "print(\"n_estimators: \",100)\n",
    "print(\"max_depth: \", 6)\n",
    "print(\"Learning Rate: \", 0.1)\n",
    "print(\"min_samples_leaf: \", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the result above, we have found the suitable hyperparameters for our model, thus we can use them to check if a better result will be obtained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bettergbr1 = GradientBoostingRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    min_samples_leaf=3\n",
    ")\n",
    "\n",
    "get_cv_results(bettergbr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do see some improvements on the mean squared error after we adjusted the hyperparameter a bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Regression Tree Model\n",
    "From definition, decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.\n",
    "Thus, in our case when we do the regression tree model, we actually use the decision tree classifer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the regression model using default paramater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regtreemo = DecisionTreeRegressor(\n",
    "    random_state=1, \n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=None,\n",
    "    max_leaf_nodes=None )\n",
    "\n",
    "regtreemo.fit(md_df[features], md_df['rent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cv_results(regtreemo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the regression model using Hyperparameters that we found, so that we can compare the results among different models better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newregtreemo = DecisionTreeRegressor(\n",
    "    random_state=1, \n",
    "    max_depth=6,\n",
    "    min_samples_leaf=3 )\n",
    "\n",
    "newregtreemo.fit(md_df[features], md_df['rent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cv_results(newregtreemo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "As we can see, the regression tree model that uses the Hyperparameters does have better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature,score in zip(features,newregtreemo.feature_importances_):\n",
    "    print(feature, ' ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve\n",
    "We can use the Learning Curves methods provided in lecture 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_values = range(1,50, 2)\n",
    "all_mu = []\n",
    "all_sigma = []\n",
    "\n",
    "for m in hp_values:\n",
    "\n",
    "    dtree=DecisionTreeClassifier(\n",
    "        criterion='entropy', \n",
    "        random_state=random_state, \n",
    "        max_depth=m,\n",
    "    )\n",
    "\n",
    "    mu, sigma = get_cv_results(dtree)\n",
    "    all_mu.append(mu)\n",
    "    all_sigma.append(sigma)\n",
    "    \n",
    "    print(m, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(hp_values, all_mu)\n",
    "plt.ylabel('Cross Validation Accuracy')\n",
    "plt.xlabel('Max Depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(hp_values, all_sigma)\n",
    "plt.ylabel('Cross Validation Std Dev.')\n",
    "plt.xlabel('Max Depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "Neural networks are a set of algorithms, modeled loosely after the human brain, that are designed to recognize patterns. They interpret sensory data through a kind of machine perception, labeling or clustering raw input.(source:https://skymind.ai/wiki/neural-network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(md_df[features])\n",
    "Y = md_df['rent'].values.reshape(-1,1)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.Sequential()\n",
    "net.add(layers.Dense(64, input_dim=train_x.shape[1], kernel_regularizer=regularizers.l1(0.1), activation='relu'))\n",
    "net.add(layers.Dropout(0.1))\n",
    "\n",
    "net.add(layers.Dense(64, kernel_regularizer=regularizers.l1(0.1), activation='relu'))\n",
    "net.add(layers.Dropout(0.1))\n",
    "\n",
    "net.add(layers.Dense(128, kernel_regularizer=regularizers.l1(0.1), activation='relu'))\n",
    "net.add(layers.Dropout(0.1))\n",
    "\n",
    "net.add(layers.Dense(256, kernel_regularizer=regularizers.l1(0.1), activation='relu'))\n",
    "net.add(layers.Dropout(0.1))\n",
    "\n",
    "net.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "net.compile(loss='mean_squared_error',\n",
    "            optimizer='adam',\n",
    "            metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9169 samples, validate on 1019 samples\n",
      "Epoch 1/150\n",
      "9169/9169 [==============================] - 1s 62us/step - loss: 9439488.9872 - mean_squared_error: 9439101.0000 - val_loss: 4170506.5745 - val_mean_squared_error: 4170093.7500\n",
      "Epoch 2/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 1970723.0375 - mean_squared_error: 1970319.0000 - val_loss: 3720449.1812 - val_mean_squared_error: 3720047.7500\n",
      "Epoch 3/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 1797370.9328 - mean_squared_error: 1796976.2500 - val_loss: 3765317.5942 - val_mean_squared_error: 3764927.5000\n",
      "Epoch 4/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 1640128.9020 - mean_squared_error: 1639741.0000 - val_loss: 3692878.1021 - val_mean_squared_error: 3692495.0000\n",
      "Epoch 5/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 1695072.3071 - mean_squared_error: 1694691.1250 - val_loss: 3572261.3766 - val_mean_squared_error: 3571882.5000\n",
      "Epoch 6/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 1596244.1298 - mean_squared_error: 1595868.2500 - val_loss: 3471047.0306 - val_mean_squared_error: 3470671.2500\n",
      "Epoch 7/150\n",
      "9169/9169 [==============================] - 0s 40us/step - loss: 1564279.5620 - mean_squared_error: 1563906.8750 - val_loss: 3551336.5128 - val_mean_squared_error: 3550966.0000\n",
      "Epoch 8/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 1601002.4664 - mean_squared_error: 1600633.0000 - val_loss: 3455062.1896 - val_mean_squared_error: 3454692.7500\n",
      "Epoch 9/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 1473200.7799 - mean_squared_error: 1472833.7500 - val_loss: 3416100.0911 - val_mean_squared_error: 3415731.7500\n",
      "Epoch 10/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 1589916.0063 - mean_squared_error: 1589551.0000 - val_loss: 3458006.0228 - val_mean_squared_error: 3457642.5000\n",
      "Epoch 11/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 1497814.2738 - mean_squared_error: 1497450.2500 - val_loss: 3275849.8268 - val_mean_squared_error: 3275482.7500\n",
      "Epoch 12/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 1475157.9218 - mean_squared_error: 1474793.5000 - val_loss: 3351915.5696 - val_mean_squared_error: 3351551.0000\n",
      "Epoch 13/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 1518612.3166 - mean_squared_error: 1518248.0000 - val_loss: 3340732.5638 - val_mean_squared_error: 3340368.0000\n",
      "Epoch 14/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 1420870.2072 - mean_squared_error: 1420507.2500 - val_loss: 3485093.8314 - val_mean_squared_error: 3484732.0000\n",
      "Epoch 15/150\n",
      "9169/9169 [==============================] - 0s 40us/step - loss: 1428763.1547 - mean_squared_error: 1428400.2500 - val_loss: 3441025.6994 - val_mean_squared_error: 3440663.7500\n",
      "Epoch 16/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 1414727.3692 - mean_squared_error: 1414364.6250 - val_loss: 3490582.4163 - val_mean_squared_error: 3490218.5000\n",
      "Epoch 17/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 1445335.1960 - mean_squared_error: 1444970.3750 - val_loss: 3272036.1998 - val_mean_squared_error: 3271669.0000\n",
      "Epoch 18/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 1403125.8970 - mean_squared_error: 1402759.0000 - val_loss: 3499636.5650 - val_mean_squared_error: 3499272.0000\n",
      "Epoch 19/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 1369728.7888 - mean_squared_error: 1369361.7500 - val_loss: 3166020.4145 - val_mean_squared_error: 3165651.2500\n",
      "Epoch 20/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 1383087.6794 - mean_squared_error: 1382718.5000 - val_loss: 3103298.5524 - val_mean_squared_error: 3102928.2500\n",
      "Epoch 21/150\n",
      "9169/9169 [==============================] - 0s 40us/step - loss: 1355993.8142 - mean_squared_error: 1355622.6250 - val_loss: 3196364.4885 - val_mean_squared_error: 3195993.7500\n",
      "Epoch 22/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 1377255.5201 - mean_squared_error: 1376883.1250 - val_loss: 3000317.9555 - val_mean_squared_error: 2999943.0000\n",
      "Epoch 23/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 1271402.6625 - mean_squared_error: 1271026.7500 - val_loss: 2963711.5430 - val_mean_squared_error: 2963334.5000\n",
      "Epoch 24/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 1332556.0191 - mean_squared_error: 1332177.7500 - val_loss: 3034633.4430 - val_mean_squared_error: 3034255.2500\n",
      "Epoch 25/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 1267105.5327 - mean_squared_error: 1266726.0000 - val_loss: 2847419.5056 - val_mean_squared_error: 2847035.0000\n",
      "Epoch 26/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 1251319.9484 - mean_squared_error: 1250935.8750 - val_loss: 2812194.5502 - val_mean_squared_error: 2811808.5000\n",
      "Epoch 27/150\n",
      "9169/9169 [==============================] - 0s 40us/step - loss: 1213532.3891 - mean_squared_error: 1213145.8750 - val_loss: 2865057.7426 - val_mean_squared_error: 2864670.5000\n",
      "Epoch 28/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 1199320.8544 - mean_squared_error: 1198931.8750 - val_loss: 2715955.8043 - val_mean_squared_error: 2715565.2500\n",
      "Epoch 29/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 1284728.2508 - mean_squared_error: 1284336.1250 - val_loss: 2875145.5043 - val_mean_squared_error: 2874755.0000\n",
      "Epoch 30/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 1196054.8530 - mean_squared_error: 1195661.5000 - val_loss: 2562893.0371 - val_mean_squared_error: 2562496.0000\n",
      "Epoch 31/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 1166732.0119 - mean_squared_error: 1166337.0000 - val_loss: 2533730.5891 - val_mean_squared_error: 2533332.5000\n",
      "Epoch 32/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 1176424.8852 - mean_squared_error: 1176026.1250 - val_loss: 2796328.1454 - val_mean_squared_error: 2795929.5000\n",
      "Epoch 33/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 1123723.8253 - mean_squared_error: 1123323.2500 - val_loss: 2786264.1390 - val_mean_squared_error: 2785864.7500\n",
      "Epoch 34/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 1111608.0092 - mean_squared_error: 1111205.1250 - val_loss: 2330362.0248 - val_mean_squared_error: 2329955.7500\n",
      "Epoch 35/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 1125652.8573 - mean_squared_error: 1125247.1250 - val_loss: 2373442.7544 - val_mean_squared_error: 2373034.2500\n",
      "Epoch 36/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 1105536.2080 - mean_squared_error: 1105127.6250 - val_loss: 2846539.1882 - val_mean_squared_error: 2846133.0000\n",
      "Epoch 37/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 1117300.5705 - mean_squared_error: 1116890.7500 - val_loss: 2405749.9021 - val_mean_squared_error: 2405338.7500\n",
      "Epoch 38/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 1109102.0278 - mean_squared_error: 1108690.6250 - val_loss: 2459113.2724 - val_mean_squared_error: 2458701.5000\n",
      "Epoch 39/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 1105413.9463 - mean_squared_error: 1105000.7500 - val_loss: 2679040.3205 - val_mean_squared_error: 2678627.2500\n",
      "Epoch 40/150\n",
      "9169/9169 [==============================] - 0s 40us/step - loss: 1065116.4535 - mean_squared_error: 1064699.6250 - val_loss: 2558920.5222 - val_mean_squared_error: 2558504.2500\n",
      "Epoch 41/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 1040853.5620 - mean_squared_error: 1040435.6250 - val_loss: 2289326.2152 - val_mean_squared_error: 2288906.2500\n",
      "Epoch 42/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 1043279.4229 - mean_squared_error: 1042859.9375 - val_loss: 2420448.2407 - val_mean_squared_error: 2420028.7500\n",
      "Epoch 43/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 1031340.5532 - mean_squared_error: 1030918.8125 - val_loss: 2630894.1705 - val_mean_squared_error: 2630474.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 1121335.7541 - mean_squared_error: 1120913.7500 - val_loss: 2383597.2294 - val_mean_squared_error: 2383174.5000\n",
      "Epoch 45/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 981618.4525 - mean_squared_error: 981193.0000 - val_loss: 2193254.7223 - val_mean_squared_error: 2192825.7500\n",
      "Epoch 46/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 1011763.1615 - mean_squared_error: 1011335.3125 - val_loss: 2532054.0707 - val_mean_squared_error: 2531628.0000\n",
      "Epoch 47/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 990110.7172 - mean_squared_error: 989682.6250 - val_loss: 2208455.8214 - val_mean_squared_error: 2208024.5000\n",
      "Epoch 48/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 984393.7737 - mean_squared_error: 983962.0625 - val_loss: 2231541.6372 - val_mean_squared_error: 2231108.2500\n",
      "Epoch 49/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 1008631.9918 - mean_squared_error: 1008198.7500 - val_loss: 2102857.4831 - val_mean_squared_error: 2102421.7500\n",
      "Epoch 50/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 996180.1548 - mean_squared_error: 995743.6875 - val_loss: 2297094.6963 - val_mean_squared_error: 2296657.5000\n",
      "Epoch 51/150\n",
      "9169/9169 [==============================] - 0s 40us/step - loss: 959741.9665 - mean_squared_error: 959304.3750 - val_loss: 2146321.5751 - val_mean_squared_error: 2145882.5000\n",
      "Epoch 52/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 1089584.5100 - mean_squared_error: 1089145.8750 - val_loss: 2183665.3531 - val_mean_squared_error: 2183226.2500\n",
      "Epoch 53/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 971654.3757 - mean_squared_error: 971214.2500 - val_loss: 2125312.2901 - val_mean_squared_error: 2124872.0000\n",
      "Epoch 54/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 915068.0442 - mean_squared_error: 914627.0625 - val_loss: 2210768.0422 - val_mean_squared_error: 2210326.7500\n",
      "Epoch 55/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 954923.6707 - mean_squared_error: 954481.0000 - val_loss: 2229806.7147 - val_mean_squared_error: 2229364.0000\n",
      "Epoch 56/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 953045.0492 - mean_squared_error: 952600.0000 - val_loss: 2131690.4118 - val_mean_squared_error: 2131245.7500\n",
      "Epoch 57/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 943547.6091 - mean_squared_error: 943102.3125 - val_loss: 2162201.9081 - val_mean_squared_error: 2161756.0000\n",
      "Epoch 58/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 920047.2412 - mean_squared_error: 919601.2500 - val_loss: 2187061.6433 - val_mean_squared_error: 2186615.0000\n",
      "Epoch 59/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 927407.0886 - mean_squared_error: 926958.6250 - val_loss: 2047010.7948 - val_mean_squared_error: 2046559.5000\n",
      "Epoch 60/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 944442.8879 - mean_squared_error: 943991.8750 - val_loss: 1996317.3138 - val_mean_squared_error: 1995865.3750\n",
      "Epoch 61/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 919205.1368 - mean_squared_error: 918752.5000 - val_loss: 2060325.4095 - val_mean_squared_error: 2059870.3750\n",
      "Epoch 62/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 950160.1218 - mean_squared_error: 949703.8750 - val_loss: 2157844.2149 - val_mean_squared_error: 2157389.5000\n",
      "Epoch 63/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 923798.7828 - mean_squared_error: 923341.6875 - val_loss: 2110157.5483 - val_mean_squared_error: 2109700.5000\n",
      "Epoch 64/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 923250.9344 - mean_squared_error: 922793.7500 - val_loss: 2121165.0737 - val_mean_squared_error: 2120707.7500\n",
      "Epoch 65/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 915690.1401 - mean_squared_error: 915232.6250 - val_loss: 2202204.8276 - val_mean_squared_error: 2201746.7500\n",
      "Epoch 66/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 902587.7329 - mean_squared_error: 902126.8125 - val_loss: 2031276.4708 - val_mean_squared_error: 2030813.8750\n",
      "Epoch 67/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 925217.1100 - mean_squared_error: 924754.3125 - val_loss: 2305255.5623 - val_mean_squared_error: 2304795.7500\n",
      "Epoch 68/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 889163.6373 - mean_squared_error: 888701.8125 - val_loss: 1951906.8672 - val_mean_squared_error: 1951443.2500\n",
      "Epoch 69/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 893270.3485 - mean_squared_error: 892805.1250 - val_loss: 1937685.0872 - val_mean_squared_error: 1937217.5000\n",
      "Epoch 70/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 914038.4202 - mean_squared_error: 913572.8750 - val_loss: 1851597.7471 - val_mean_squared_error: 1851130.8750\n",
      "Epoch 71/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 903473.2677 - mean_squared_error: 903006.6875 - val_loss: 1964939.3229 - val_mean_squared_error: 1964473.0000\n",
      "Epoch 72/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 835959.8139 - mean_squared_error: 835492.8125 - val_loss: 1785551.3513 - val_mean_squared_error: 1785081.8750\n",
      "Epoch 73/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 903120.2754 - mean_squared_error: 902650.6875 - val_loss: 2103145.2126 - val_mean_squared_error: 2102673.5000\n",
      "Epoch 74/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 845351.4770 - mean_squared_error: 844878.8125 - val_loss: 2399958.9932 - val_mean_squared_error: 2399488.0000\n",
      "Epoch 75/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 949245.3677 - mean_squared_error: 948769.4375 - val_loss: 2279672.0728 - val_mean_squared_error: 2279199.5000\n",
      "Epoch 76/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 961487.1714 - mean_squared_error: 961013.1250 - val_loss: 1923670.0774 - val_mean_squared_error: 1923195.2500\n",
      "Epoch 77/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 843698.6336 - mean_squared_error: 843222.6875 - val_loss: 2147851.2890 - val_mean_squared_error: 2147377.0000\n",
      "Epoch 78/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 876264.7053 - mean_squared_error: 875788.3125 - val_loss: 2597513.2598 - val_mean_squared_error: 2597040.5000\n",
      "Epoch 79/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 858005.9032 - mean_squared_error: 857529.3750 - val_loss: 2300754.6723 - val_mean_squared_error: 2300280.7500\n",
      "Epoch 80/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 815825.1284 - mean_squared_error: 815346.5625 - val_loss: 2217687.3454 - val_mean_squared_error: 2217211.5000\n",
      "Epoch 81/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 860917.7025 - mean_squared_error: 860439.5625 - val_loss: 1972286.7346 - val_mean_squared_error: 1971806.6250\n",
      "Epoch 82/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 827432.5984 - mean_squared_error: 826953.6250 - val_loss: 1812656.3881 - val_mean_squared_error: 1812174.2500\n",
      "Epoch 83/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 902384.2609 - mean_squared_error: 901904.7500 - val_loss: 1774647.7801 - val_mean_squared_error: 1774166.6250\n",
      "Epoch 84/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 828149.0947 - mean_squared_error: 827667.7500 - val_loss: 1989416.3407 - val_mean_squared_error: 1988935.5000\n",
      "Epoch 85/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 866686.4784 - mean_squared_error: 866203.6250 - val_loss: 1909215.2988 - val_mean_squared_error: 1908731.1250\n",
      "Epoch 86/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 907806.3745 - mean_squared_error: 907320.5000 - val_loss: 2033241.5653 - val_mean_squared_error: 2032756.3750\n",
      "Epoch 87/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 854978.2572 - mean_squared_error: 854492.0000 - val_loss: 1699034.4030 - val_mean_squared_error: 1698544.3750\n",
      "Epoch 88/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 860579.5763 - mean_squared_error: 860091.1875 - val_loss: 1751091.9441 - val_mean_squared_error: 1750598.8750\n",
      "Epoch 89/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 783979.6717 - mean_squared_error: 783489.8750 - val_loss: 1841920.3186 - val_mean_squared_error: 1841429.1250\n",
      "Epoch 90/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 807682.9576 - mean_squared_error: 807191.3750 - val_loss: 1850560.8928 - val_mean_squared_error: 1850067.7500\n",
      "Epoch 91/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 819229.5413 - mean_squared_error: 818737.6250 - val_loss: 2097258.3710 - val_mean_squared_error: 2096766.3750\n",
      "Epoch 92/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 769031.9514 - mean_squared_error: 768537.8750 - val_loss: 1871964.0149 - val_mean_squared_error: 1871467.1250\n",
      "Epoch 93/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 793991.9685 - mean_squared_error: 793494.5625 - val_loss: 2068356.4143 - val_mean_squared_error: 2067859.8750\n",
      "Epoch 94/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 767399.4476 - mean_squared_error: 766902.0625 - val_loss: 1849853.0783 - val_mean_squared_error: 1849357.5000\n",
      "Epoch 95/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 774442.2222 - mean_squared_error: 773945.3125 - val_loss: 1849909.0934 - val_mean_squared_error: 1849411.2500\n",
      "Epoch 96/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 783518.4959 - mean_squared_error: 783021.5625 - val_loss: 1784178.2515 - val_mean_squared_error: 1783680.6250\n",
      "Epoch 97/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 827438.6709 - mean_squared_error: 826943.0000 - val_loss: 1741996.6000 - val_mean_squared_error: 1741496.2500\n",
      "Epoch 98/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 835502.4325 - mean_squared_error: 835003.6875 - val_loss: 2083319.9345 - val_mean_squared_error: 2082823.3750\n",
      "Epoch 99/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 794846.2996 - mean_squared_error: 794347.0000 - val_loss: 1751893.4894 - val_mean_squared_error: 1751392.6250\n",
      "Epoch 100/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 794922.6306 - mean_squared_error: 794420.6250 - val_loss: 1798860.6330 - val_mean_squared_error: 1798356.8750\n",
      "Epoch 101/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 789981.3137 - mean_squared_error: 789476.5000 - val_loss: 1861134.3285 - val_mean_squared_error: 1860631.6250\n",
      "Epoch 102/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 791444.9540 - mean_squared_error: 790940.8125 - val_loss: 1964784.0574 - val_mean_squared_error: 1964279.3750\n",
      "Epoch 103/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 805464.5772 - mean_squared_error: 804958.6250 - val_loss: 1972061.7788 - val_mean_squared_error: 1971555.1250\n",
      "Epoch 104/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 773719.9047 - mean_squared_error: 773212.3750 - val_loss: 2328336.2404 - val_mean_squared_error: 2327829.2500\n",
      "Epoch 105/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 729083.3140 - mean_squared_error: 728574.1875 - val_loss: 1676733.6223 - val_mean_squared_error: 1676221.1250\n",
      "Epoch 106/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 777853.6930 - mean_squared_error: 777343.0625 - val_loss: 1715149.7554 - val_mean_squared_error: 1714637.5000\n",
      "Epoch 107/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 773973.8626 - mean_squared_error: 773461.2500 - val_loss: 1855472.5684 - val_mean_squared_error: 1854956.7500\n",
      "Epoch 108/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 834779.7323 - mean_squared_error: 834264.8125 - val_loss: 2133312.3716 - val_mean_squared_error: 2132804.0000\n",
      "Epoch 109/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 749269.3655 - mean_squared_error: 748757.3125 - val_loss: 1949322.1233 - val_mean_squared_error: 1948808.3750\n",
      "Epoch 110/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 820300.1411 - mean_squared_error: 819784.6875 - val_loss: 1985574.1025 - val_mean_squared_error: 1985059.6250\n",
      "Epoch 111/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 801975.1418 - mean_squared_error: 801460.5000 - val_loss: 1563288.2436 - val_mean_squared_error: 1562771.3750\n",
      "Epoch 112/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 804683.7571 - mean_squared_error: 804168.4375 - val_loss: 1640819.2005 - val_mean_squared_error: 1640301.7500\n",
      "Epoch 113/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 860815.4826 - mean_squared_error: 860299.1250 - val_loss: 2166126.0705 - val_mean_squared_error: 2165611.5000\n",
      "Epoch 114/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 768573.2444 - mean_squared_error: 768056.8125 - val_loss: 1977155.0120 - val_mean_squared_error: 1976638.6250\n",
      "Epoch 115/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 780527.3396 - mean_squared_error: 780011.4375 - val_loss: 2168007.8606 - val_mean_squared_error: 2167494.0000\n",
      "Epoch 116/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 718657.3625 - mean_squared_error: 718139.7500 - val_loss: 1935212.9551 - val_mean_squared_error: 1934694.5000\n",
      "Epoch 117/150\n",
      "9169/9169 [==============================] - 0s 36us/step - loss: 764255.9493 - mean_squared_error: 763737.7500 - val_loss: 1960153.8223 - val_mean_squared_error: 1959636.6250\n",
      "Epoch 118/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 770465.6162 - mean_squared_error: 769946.8750 - val_loss: 2267663.4099 - val_mean_squared_error: 2267147.2500\n",
      "Epoch 119/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 715971.3235 - mean_squared_error: 715452.0000 - val_loss: 1822045.6524 - val_mean_squared_error: 1821523.2500\n",
      "Epoch 120/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 791765.6871 - mean_squared_error: 791244.9375 - val_loss: 1860796.7592 - val_mean_squared_error: 1860275.8750\n",
      "Epoch 121/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 693654.0691 - mean_squared_error: 693130.5625 - val_loss: 1709208.9338 - val_mean_squared_error: 1708685.0000\n",
      "Epoch 122/150\n",
      "9169/9169 [==============================] - 0s 40us/step - loss: 699726.1003 - mean_squared_error: 699199.3125 - val_loss: 1860015.3484 - val_mean_squared_error: 1859488.2500\n",
      "Epoch 123/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 790860.4992 - mean_squared_error: 790333.9375 - val_loss: 2482469.6968 - val_mean_squared_error: 2481944.0000\n",
      "Epoch 124/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 782360.8308 - mean_squared_error: 781832.6875 - val_loss: 1995286.3935 - val_mean_squared_error: 1994760.6250\n",
      "Epoch 125/150\n",
      "9169/9169 [==============================] - 0s 40us/step - loss: 732010.2550 - mean_squared_error: 731480.7500 - val_loss: 1771204.9268 - val_mean_squared_error: 1770674.6250\n",
      "Epoch 126/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 688655.1763 - mean_squared_error: 688126.5000 - val_loss: 1860247.0687 - val_mean_squared_error: 1859717.0000\n",
      "Epoch 127/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 657413.7818 - mean_squared_error: 656883.9375 - val_loss: 1629502.7453 - val_mean_squared_error: 1628971.7500\n",
      "Epoch 128/150\n",
      "9169/9169 [==============================] - 0s 40us/step - loss: 731601.4402 - mean_squared_error: 731072.4375 - val_loss: 1924744.6528 - val_mean_squared_error: 1924215.8750\n",
      "Epoch 129/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 718895.7112 - mean_squared_error: 718366.3125 - val_loss: 1720534.5915 - val_mean_squared_error: 1720005.1250\n",
      "Epoch 130/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9169/9169 [==============================] - 0s 38us/step - loss: 763063.6135 - mean_squared_error: 762536.1250 - val_loss: 1957301.6408 - val_mean_squared_error: 1956773.6250\n",
      "Epoch 131/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 737854.5669 - mean_squared_error: 737323.8750 - val_loss: 1869961.2300 - val_mean_squared_error: 1869428.1250\n",
      "Epoch 132/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 663983.6154 - mean_squared_error: 663448.8750 - val_loss: 1679475.4725 - val_mean_squared_error: 1678939.2500\n",
      "Epoch 133/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 763707.5336 - mean_squared_error: 763173.5625 - val_loss: 1800012.7746 - val_mean_squared_error: 1799477.6250\n",
      "Epoch 134/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 749428.0405 - mean_squared_error: 748892.0625 - val_loss: 1981046.4145 - val_mean_squared_error: 1980511.5000\n",
      "Epoch 135/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 662876.3919 - mean_squared_error: 662337.5625 - val_loss: 1771924.4550 - val_mean_squared_error: 1771384.6250\n",
      "Epoch 136/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 700291.9745 - mean_squared_error: 699752.9375 - val_loss: 1708549.3052 - val_mean_squared_error: 1708008.2500\n",
      "Epoch 137/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 834977.7621 - mean_squared_error: 834438.6250 - val_loss: 1900445.8898 - val_mean_squared_error: 1899907.1250\n",
      "Epoch 138/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 684194.7269 - mean_squared_error: 683655.5000 - val_loss: 1745928.1769 - val_mean_squared_error: 1745387.3750\n",
      "Epoch 139/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 712863.0508 - mean_squared_error: 712321.7500 - val_loss: 1670054.1609 - val_mean_squared_error: 1669509.6250\n",
      "Epoch 140/150\n",
      "9169/9169 [==============================] - 0s 37us/step - loss: 796698.9537 - mean_squared_error: 796157.0000 - val_loss: 2832716.7314 - val_mean_squared_error: 2832179.5000\n",
      "Epoch 141/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 754687.1297 - mean_squared_error: 754147.0625 - val_loss: 1853257.4616 - val_mean_squared_error: 1852717.1250\n",
      "Epoch 142/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 716748.0648 - mean_squared_error: 716209.2500 - val_loss: 2029988.0517 - val_mean_squared_error: 2029449.6250\n",
      "Epoch 143/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 710929.9865 - mean_squared_error: 710390.3750 - val_loss: 1725646.3693 - val_mean_squared_error: 1725101.6250\n",
      "Epoch 144/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 677514.7426 - mean_squared_error: 676970.3125 - val_loss: 1816808.2936 - val_mean_squared_error: 1816262.2500\n",
      "Epoch 145/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 670460.8452 - mean_squared_error: 669915.0000 - val_loss: 1833231.8419 - val_mean_squared_error: 1832687.7500\n",
      "Epoch 146/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 714986.1150 - mean_squared_error: 714441.2500 - val_loss: 2069749.8120 - val_mean_squared_error: 2069206.8750\n",
      "Epoch 147/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 657591.4950 - mean_squared_error: 657046.2500 - val_loss: 1690595.1538 - val_mean_squared_error: 1690049.5000\n",
      "Epoch 148/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 617505.1488 - mean_squared_error: 616959.1875 - val_loss: 1924021.6623 - val_mean_squared_error: 1923475.6250\n",
      "Epoch 149/150\n",
      "9169/9169 [==============================] - 0s 38us/step - loss: 695989.3545 - mean_squared_error: 695441.3750 - val_loss: 1772284.5121 - val_mean_squared_error: 1771735.5000\n",
      "Epoch 150/150\n",
      "9169/9169 [==============================] - 0s 39us/step - loss: 699532.7028 - mean_squared_error: 698983.1250 - val_loss: 2239376.6157 - val_mean_squared_error: 2238829.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x25bbd327f08>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(train_x, train_y, epochs=150, batch_size=64, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1373529.171673119"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test_y, net.predict(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Although the DL Neural Network seems to provide a better result on mean squared errors but it is really unstable** \n",
    "\n",
    "we have ran few test run on it, and each time it gives different results range from 853411.6171418771 to around 1,300,000.\n",
    "Therefore, we might still choose Gradient Boosting Regression as the most suitable model, since it provides a overall better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

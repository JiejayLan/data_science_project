# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_AY0HtKd2_TNQXjYPA_s17bTWvxyo-gb
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from sklearn.linear_model import LinearRegression

# %matplotlib inline

raw_df = pd.read_csv('https://grantmlong.com/data/SE_rents2018_train.csv', index_col=0)
raw_df.head(20)
raw_df.columns

"""# Data Summarize"""

raw_df.describe()

raw_df.shape

raw_df.info()

raw_df['rent'].hist(bins=100)

"""### Seperate all features into continuous, categorical and binary features.

For those none relatived features, we have excluded them from the features grouping: 
- addr_unit: no relationship
- building_id: no relationship
- addr_lat: hard to analyze latitude
- addr_lon: hard to analyze longtitude
- bin: no relationship
- bbl: no relationshio
- description: hard to build a NLP model
- unit: no relationship
"""

continuous_features =['bathrooms','bedrooms','size_sqft','floor_count','year_built','min_to_subway','floornumber' ]
caterigal_features =['addr_street','addr_city','addr_zip','neighborhood','borough','line' ]
binary_features = ['has_doorman', 'has_elevator', 'has_fireplace', 'has_dishwasher','is_furnished', 'has_gym', 'allows_pets', 
                   'has_washer_dryer','has_garage', 'has_roofdeck', 'has_concierge', 'has_pool', 'has_garden',
                   'has_childrens_playroom', 'no_fee', ]

unique_count = [] 
for feature in raw_df.columns:
  unique_count.append(raw_df[feature].nunique())
count_df = pd.DataFrame({'Feature':raw_df.columns,'unique count': unique_count})
count_df

"""### use pair coorelation for continuous features"""

continuous_df = raw_df[continuous_features+['rent']]
continuous_df.corr()['rent'][:-1]

"""### Create a scatterplot of continuous features."""

sns.pairplot(data = raw_df,  y_vars=['rent'],x_vars=continuous_features)

"""### Check coorelation for binary features"""

raw_df[binary_features+['rent']].corr()['rent'][:-1]
coor_results= []

for feature in binary_features:
  df = raw_df.groupby([feature]).aggregate(['mean'])['rent']
  df[feature]= df.index
  coor_results.append(df.corr().iloc[0][1])
coor_df = pd.DataFrame({'Coorelation': coor_results,'Feature':binary_features})
coor_df

"""As we can see in the correlation table, all binrary features highly affected the rents. When we build the models, we should include all binary features.

### Check coorelation for categorical features
Need to do the binary first, then check the coorelation for categorical features, should be doen by group two
"""
"""
### Clean up the outside dataset dataframe
Need to drop unnecessary columns and only display the useful information to find the average income amount for each zip code
"""
raw_outside_data=pd.read_csv('https://www.irs.gov/pub/irs-soi/17zpallagi.csv', index_col=0)
raw_outside_data.columns

raw_outside_data.describe()

# Only keep the useful data for calculations
# agi_stub stands for Size of adjusted gross income
# M1 stands for the Number of returns
# A02650 stands for Total income amount
# We need to find the average income
raw_outside_data = raw_outside_data.loc[raw_outside_data['STATE']=='NY']
raw_outside_data = raw_outside_data[['STATE','zipcode','agi_stub','N1', 'A02650']]
raw_outside_data = raw_outside_data.loc[raw_outside_data['zipcode']<99999]
raw_outside_data = raw_outside_data.loc[raw_outside_data['zipcode']>0]

raw_outside_data.head(10)

import csv
def calculate_avg_income():
    with open('data/17ny.csv', mode='w') as avg_file:
        thewriter = csv.writer(avg_file)
        thewriter.writerow(['addr_zip','addr_zip_average_income'])
        for zipcode in range(10001, 14906):
            current_sum=np.where(raw_outside_data['zipcode']==zipcode, raw_outside_data['A02650'],0).sum()
            current_returns=np.where(raw_outside_data['zipcode']==zipcode, raw_outside_data['N1'],0).sum()  
            avg_income=(current_sum*1000)/current_returns
            if(avg_income>0):
                thewriter.writerow([zipcode,avg_income])
    
import warnings
warnings.filterwarnings('ignore')
calculate_avg_income()

# read the avg income based on zip code file 
outside_data=pd.read_csv("data/17ny.csv")
outside_data.head(5)

# Merge the raw dataset and the outside dataset by addr_zip
raw_df=raw_df.reset_index().merge(outside_data, how="left",on='addr_zip').set_index('rental_id')
raw_df.head(5)

### Merged Data Summarize

raw_df.describe() 

raw_df.shape

raw_df.info()

